{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0a98ecc",
   "metadata": {},
   "source": [
    "### Twitter scraper \n",
    "\n",
    "This notebook scrapes tweets by using the snscrape module. The parameters below work as follows: \n",
    "- **maxTweets**: Number of daily tweets you want to download (2500 tweets for 120 days took me about 9 hours to scrape)\n",
    "- **date_start**: Starting date for the download of tweets \n",
    "- **ndays**: Number of days for your analysis \n",
    "- **query_text**: Text to search for (in my case, I first used Ukraine and then Russia)\n",
    "- **lang**: Language of the tweets that you want to scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f809f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import snscrape.modules.twitter as sntwitter\n",
    "import pandas as pd \n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d4ed00",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "maxTweets = 2500\n",
    "date_start = 'Dec 01 2021'\n",
    "ndays = 120 \n",
    "query_text = 'Ukraine' #You can edit this to be any word(s) in your query! \n",
    "lang = 'en'\n",
    "\n",
    "ls = []\n",
    "\n",
    "for day in range(ndays):\n",
    "  \n",
    "    datetime_object = datetime.strptime(date_start, '%b %d %Y') + timedelta(days=day) \n",
    "    print(f'Started scraping date: {datetime_object})\n",
    "  \n",
    "    sd = str(int(datetime_object.timestamp())) \n",
    "    ed = str(int((datetime_object + timedelta(days=1)).timestamp())) \n",
    "          \n",
    "    for i,tweet in enumerate(sntwitter.TwitterSearchScraper(f'{query_text} + lang:{lang} since:{sd} until:{ed}').get_items()):\n",
    "        ls.append([tweet.date, tweet.content.replace('\\n',''), tweet.id])\n",
    "        if i > maxTweets :\n",
    "            break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8596cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(ls)\n",
    "print(f'Total tweets scraped: {len(df)}')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d3abd5",
   "metadata": {},
   "source": [
    "Saving with tilde (~) separator to avoid any tweet splitting up because the user added a '\\n' or a ';' in their tweet! \\\n",
    "I suggest to keep it like this and just read the csv by specifying the same separator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd7cf09",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.to_csv(f'{query_text}_{lang}_{ndays}.csv', sep = '~')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9cdd185",
   "metadata": {},
   "source": [
    "More info at: \n",
    "\n",
    "https://github.com/igorbrigadir/twitter-advanced-search \\\n",
    "https://medium.com/swlh/how-to-scrape-tweets-by-location-in-python-using-snscrape-8c870fa6ec25"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
